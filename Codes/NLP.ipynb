{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "from nltk import pos_tag"
      ],
      "metadata": {
        "id": "Ndol07xayHyy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "392VQF1AypgD",
        "outputId": "ab34a3cd-3d0a-4c35-ef26-5556bb2b6eb7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ycjs7jZWxsuh",
        "outputId": "28520a7e-555a-456a-a2c3-49d3ba45a943"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['nltk', 'lead', 'platform', 'build', 'python', 'program', 'work', 'human', 'languag', 'data']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def get_wordnet_pos(treebank_tag):\n",
        "    if treebank_tag.startswith('J'):\n",
        "        return 'a'\n",
        "    elif treebank_tag.startswith('V'):\n",
        "        return 'v'\n",
        "    elif treebank_tag.startswith('N'):\n",
        "        return 'n'\n",
        "    elif treebank_tag.startswith('R'):\n",
        "        return 'r'\n",
        "    else:\n",
        "        return None\n",
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [word for word in tokens if word.isalnum()]\n",
        "    tokens = [word.lower() for word in tokens]\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens_pos = pos_tag(tokens)\n",
        "    tokens = [lemmatizer.lemmatize(word, pos=get_wordnet_pos(pos_tag)) for word, pos_tag in tokens_pos if get_wordnet_pos(pos_tag) is not None]\n",
        "    stemmer = PorterStemmer()\n",
        "    tokens = [stemmer.stem(word) for word in tokens]\n",
        "    return tokens\n",
        "text = \"NLTK is a leading platform for building Python programs to work with human language data.\"\n",
        "processed_text = preprocess_text(text)\n",
        "print(processed_text)"
      ]
    }
  ]
}